{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded = pd.read_csv(\"../data/train_store_encoded_onehot.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/svjack/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "store_df = pd.read_csv(\"../data/store.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_df = store_df.apply(lambda x: (x[\"Store\"], x[\"StoreType\"] + x[\"Assortment\"]), axis = 1).map(lambda x: x[-1]).copy().reset_index()\n",
    "cate_df.columns = [\"Store\", \"cate\"]\n",
    "cate_df[\"Store\"] = cate_df[\"Store\"] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_days_num(data_df, cate_df):\n",
    "    import gc\n",
    "    data_df[\"Date\"] = pd.to_datetime(data_df[\"Date\"])\n",
    "    merge_df = pd.merge(data_df[[\"Date\", \"Store\", \"Sales\"]], cate_df, on = \"Store\", how = \"inner\")\n",
    "    print(\"merge_df shape : {}\".format(merge_df.shape))\n",
    "    from functools import reduce\n",
    "    ordered_intersection_dates = sorted(pd.to_datetime(sorted(reduce(lambda a, b: a.intersection(b),map(lambda x: set(x.tolist()),merge_df.groupby(\"cate\").apply(dict).map(lambda inner_dict:inner_dict[\"Date\"]).values.tolist())))))\n",
    "    ordered_intersection_dates = pd.Series(ordered_intersection_dates)\n",
    "    #return ordered_intersection_dates\n",
    "    sales_date_intersection = merge_df.copy()\n",
    "    del merge_df\n",
    "    gc.collect()\n",
    "    sales_date_intersection = sales_date_intersection[sales_date_intersection[\"Date\"].isin(ordered_intersection_dates)].copy()\n",
    "    def transform_dict_to_df(row):\n",
    "        Store, dict_ = row[\"cate\"], row[0]\n",
    "        Date = dict_[\"Date\"].tolist()\n",
    "        Sales = dict_[\"Sales\"].tolist()\n",
    "        df = pd.DataFrame(list(zip(*[Date, Sales])))\n",
    "        df.columns = [\"Date\", Store]\n",
    "        return df\n",
    "    before_reduce_list = sales_date_intersection.groupby(\"cate\").apply(dict).reset_index().apply(\n",
    "    transform_dict_to_df\n",
    ", axis = 1).values.tolist()\n",
    "    #return before_reduce_list\n",
    "    before_reduce_list = list(map(lambda x: x.groupby(\"Date\").sum().reset_index(), before_reduce_list))\n",
    "    sales_cate_format_df = reduce(lambda a, b: pd.merge(a, b, on = \"Date\", how = \"inner\"), before_reduce_list)\n",
    "    return sales_cate_format_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge_df shape : (1001379, 4)\n"
     ]
    }
   ],
   "source": [
    "sales_cate_format_df = calculate_days_num(train_df, cate_df[cate_df[\"cate\"].isin(cate_df[\"cate\"].value_counts()[cate_df[\"cate\"].value_counts() > 70].index.tolist())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_cate_format_df[\"total\"] = sales_cate_format_df.iloc[:, 1:].apply(lambda x: x.sum(), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "sales_cate_format_df_up = sales_cate_format_df[sales_cate_format_df.iloc[:, 1:].apply(lambda x: reduce(lambda a, b: a * b ,map(int,map(bool, x))), axis = 1) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sales_cate_format_df_up.copy()\n",
    "df.index = pd.to_datetime(df[\"Date\"])\n",
    "dates = df[\"Date\"].copy()\n",
    "del df[\"Date\"]\n",
    "df = df.asfreq(\"D\")\n",
    "df = df.interpolate(method = \"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_reduce_by_cate_df = pd.merge(cate_df, train_encoded, on = \"Store\", how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_reduce_by_cate_df[\"id\"] = before_reduce_by_cate_df[[\"cate\", \"Date\"]].apply(lambda x: \"{}_{}\".format(x[\"cate\"], x[\"Date\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_by_id = before_reduce_by_cate_df[set(before_reduce_by_cate_df.columns.tolist()).difference(set([\"Store\", \"cate\"]))].groupby(\"id\").apply(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_agg_measure(same_id_df, agg_funcs = {\"max\":np.max, \"min\":np.min, \"count\":len, \"mean\":np.mean}):\n",
    "    if \"id\" in same_id_df.columns.tolist():\n",
    "        del same_id_df[\"id\"]\n",
    "    same_id_df[\"Date\"] = pd.to_datetime(same_id_df[\"Date\"]).map(lambda x: (x - pd.to_datetime(\"1970-01-01\")).days)\n",
    "    agg_series_dict = dict(map(lambda t2: (t2[0] ,same_id_df.apply(t2[-1], axis = 0)), agg_funcs.items()))\n",
    "    def rename_index(s, agg_name):\n",
    "        s.index = list(map(lambda index: \"{}_{}\".format(index, agg_name) ,s.index.tolist()))\n",
    "        return s\n",
    "    agg_series_dict = dict(map(lambda t2: (t2[0] ,rename_index(t2[1], t2[0])), agg_series_dict.items()))\n",
    "    return pd.concat(list(agg_series_dict.values()), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_part = pd.concat(reduce_by_id.map(lambda dict_: produce_agg_measure(pd.DataFrame.from_dict(dict(map(lambda t2: (t2[0], t2[1].tolist()) ,dict_.items()))))).tolist(), axis = 1)\n",
    "data_part.columns = reduce_by_id.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data(input_df, cate):\n",
    "    req_part = input_df[filter(lambda col: col.startswith(cate),input_df.columns.tolist())].copy()\n",
    "    req_part.columns = list(map(lambda col: col[3:], req_part.columns.tolist()))\n",
    "    req_part = req_part.T\n",
    "    req_part.columns = list(map(lambda col: \"{}_{}\".format(col, cate), req_part.columns.tolist()))\n",
    "    req_part.index = pd.to_datetime(req_part.index)\n",
    "    return req_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_dict = dict(map(lambda col: (col, retrieve_data(data_part, col)) ,set(df.columns.tolist()).difference(set([\"total\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_total_part(lookup_dict):\n",
    "    from functools import reduce\n",
    "    colnames = list(map(lambda x: x[:-3], list(lookup_dict.values())[0].columns.tolist()))\n",
    "    keys = list(lookup_dict.keys())\n",
    "    cols = list(set(map(lambda x: x[:x.rfind(\"_\")], colnames)))\n",
    "    aggs = list(set(map(lambda x: x[x.rfind(\"_\") + 1:], colnames)))\n",
    "    \n",
    "    vals_list = []\n",
    "    for col in cols:\n",
    "        for agg_name in aggs:\n",
    "            req = []\n",
    "            for cate_key in keys:\n",
    "                s = lookup_dict[cate_key][\"{}_{}_{}\".format(col, agg_name, cate_key)]\n",
    "                req.append(s)\n",
    "            if agg_name == \"max\":\n",
    "                val_s = pd.concat(req, axis = 1).dropna().apply(np.max, axis = 1)\n",
    "            elif agg_name == \"min\":\n",
    "                val_s = pd.concat(req, axis = 1).dropna().apply(np.min, axis = 1)\n",
    "            elif agg_name == \"count\":\n",
    "                val_s = pd.concat(req, axis = 1).dropna().apply(np.sum, axis = 1)\n",
    "            else:\n",
    "                val_s = pd.concat(req, axis = 1).dropna().apply(np.mean, axis = 1)\n",
    "            val_s.name = \"{}_{}_{}\".format(col, agg_name, \"total\")\n",
    "            vals_list.append(val_s)\n",
    "    return pd.concat(vals_list, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_part = retrieve_total_part(lookup_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_df = reduce(lambda a, b: pd.merge(a, b, left_index=True, right_index = True, how = \"inner\"), lookup_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_part_asfreq_D = total_data_part.asfreq(\"D\").sort_index().fillna(method = \"pad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_df_asfreq_D = lookup_df.asfreq(\"D\").sort_index().fillna(method = \"pad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_add_lookup = pd.merge(df, lookup_df_asfreq_D, left_index = True, right_index =True, how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_add_lookup = pd.merge(df_add_lookup, total_data_part_asfreq_D, left_index = True, right_index =True, how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_add_lookup.to_csv(\"../data/df_add_lookup.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
